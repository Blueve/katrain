{
    "engine": {
        "katago": "KataGo/katago-bs",
        "model": "models/b15-1.3.2.txt.gz",
        "config": "KataGo/analysis_config.cfg",
        "threads": 8,
        "max_visits": 500,
        "max_time": 3.0,
        "enable_ownership": true
    },
    "files": {
        "sgf_load": "~/Downloads",
        "sgf_save": "./sgfout"
    },
    "game": {
        "init_size": 19,
        "init_komi": {
            "19": 6.5
        },
        "sweep_visits_frac": 0.05
    },
    "trainer": {
        "num_undo_prompts": [
            1,
            1,
            1,
            0.5,
            0,
            0
        ],
        "eval_thresholds": [
            12,
            6,
            3,
            1.5,
            0.5,
            0
        ],
        "eval_off_show_last": 3,
        "eval_show_ai": false
    },
    "ai": {
        "Default": {
            "_help_right": "No settings available here, strength is mainly affected by `max_visits` and `model` in the main settings `engine` section.",
            "_help_left": ""
        },
        "Balance": {
            "target_score": 2,
            "random_loss": 1,
            "max_loss": 5,
            "min_visits": 20,
            "_help_right": "Will try to win by `target_score`, lose at most `random_loss` when behind and `max_loss` when ahead.",
            "_help_left": "Never plays moves with less than `min_visits` visits, so also check engine settings."
        },
        "Jigo": {
            "target_score": 0.5,
            "_help_right": "Will try to win by `target_score`, without further restrictions.",
            "_help_left": "Also affected by engine settings such as `max_visits`."
        },
        "Policy": {
            "_help_right": "No settings available for this mode, strength is mainly affected by `model` in engine settings, but should be high dan regardless.",
            "_help_left": ""
        },
        "P+Weighted": {
            "_help_right": "Strength is mainly affected by `model` in engine settings.",
            "_help_left": "`pick_override` determines when top move is chosen without randomness, and is effectively disabled by default (1.0).",
            "pick_override": 1.0
        },
        "P+Noise": {
            "pick_override": 0.95,
            "noise_strength": 0.8,
            "_help_right": "Adds `noise_strength` noise to the policy and plays the top move.",
            "_help_left": "Plays top move if policy value is above `pick_override` to avoid obvious mistakes. Noise above 0.9 is near random, below 0.7 is fairly strong."
        },
        "P+Pick": {
            "pick_override": 0.95,
            "pick_n": 5,
            "pick_frac": 0.33,
            "_help_right": "Picks `pick_n + pick_frac * <number of legal moves>` at random and plays the best one. Change `pick_frac` to make it see more moves.",
            "_help_left": "Plays top move if policy value is above `pick_override` to avoid obvious mistakes."
        },
        "P+Local": {
            "pick_override": 0.95,
            "stddev": 1.5,
            "pick_n": 15,
            "pick_frac": 0.0,
            "_help_right": "Samples `pick_n + pick_frac * <number of legal moves>` near the last move and plays the best one.",
            "_help_left": "Lower `stddev` makes it prefer closer moves."
        },
        "P+Tenuki": {
            "pick_override": 0.90,
            "stddev": 7.5,
            "pick_n": 20,
            "pick_frac": 0.4,
            "_help_right": "Samples `pick_n + pick_frac * <number of legal moves>` away from the last move and plays the best one.",
            "_help_left": "Increase `stddev` makes it prefer moves further away."
        },
        "P+Influence": {
            "pick_override": 0.95,
            "pick_n": 5,
            "pick_frac": 0.4,
            "line_weight": 10,
            "_help_right": "Samples `pick_n + pick_frac * <number of legal moves>` and plays the best one, biased towards the center.",
            "_help_left": "Increase `line_weight` to penalize moves near the edge more."
        },
        "P+Territory": {
            "pick_override": 0.95,
            "pick_n": 5,
            "pick_frac": 0.4,
            "line_weight": 5,
            "_help_right": "Samples `pick_n + pick_frac * <number of legal moves>` and plays the best one, biased towards the edge.",
            "_help_left": "Increase `line_weight` to penalize moves closer to the center more."
        }
    },
    "board_ui": {
        "starpoint_size": 0.1,
        "stone_size": 0.475,
        "eval_dot_max_size": 0.5,
        "stones": {
            "B": [
                0.05,
                0.05,
                0.05
            ],
            "W": [
                0.95,
                0.95,
                0.95
            ]
        },
        "outline": {
            "B": [
                0.3,
                0.3,
                0.3,
                0.5
            ],
            "W": [
                0.7,
                0.7,
                0.7,
                0.5
            ]
        },
        "ghost_alpha": 0.5,
        "top_move_x_alpha": 0.3,
        "child_scale": 0.95,
        "eval_colors": [
            [
                0.447,
                0.129,
                0.42,
                1
            ],
            [
                0.8,
                0,
                0,
                1
            ],
            [
                0.9,
                0.4,
                0.1,
                1
            ],
            [
                0.85,
                0.89,
                0.3,
                1
            ],
            [
                0.67,
                0.9,
                0.18,
                1
            ],
            [
                0.117,
                0.588,
                0,
                1
            ]
        ],
        "line_color": [
            0,
            0,
            0
        ],
        "policy_color": [
            0.9,
            0.2,
            0.8
        ]
    },
    "debug": {
        "level": 2
    }
}